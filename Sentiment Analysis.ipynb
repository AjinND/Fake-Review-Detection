{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MULTINOMIAL NAIVE BAYES\n",
      "[[73 20]\n",
      " [ 8 61]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.84        93\n",
      "           1       0.75      0.88      0.81        69\n",
      "\n",
      "    accuracy                           0.83       162\n",
      "   macro avg       0.83      0.83      0.83       162\n",
      "weighted avg       0.84      0.83      0.83       162\n",
      "\n",
      "0.8271604938271605\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_curve, average_precision_score\n",
    "\n",
    "def get_data_frame():\n",
    "    dataset = pd.read_csv('Sentiment_Analysis_Dataset/labelled.csv')\n",
    "\n",
    "    # get positive class\n",
    "    class_positive = dataset[dataset['Label'] == '__label__2']\n",
    "\n",
    "    # get negative class\n",
    "    class_negative = dataset[dataset['Label'] == '__label__1']\n",
    "\n",
    "    # under sample positive class randomly with the size of negative class\n",
    "    positive_under = class_positive.sample(class_negative.shape[0],replace=True)\n",
    "\n",
    "    # concatenate negative and new under sampled positive class\n",
    "    df_test_under = pd.concat([positive_under, class_negative], axis=0)\n",
    "\n",
    "    return df_test_under\n",
    "\n",
    "def split_train_test(data):\n",
    "    \n",
    "    # creating the feature matrix\n",
    "    matrix = CountVectorizer(max_features=1000, stop_words=\"english\")\n",
    "    X = matrix.fit_transform(data.iloc[:, -1].astype('U')).toarray()\n",
    "    y_tmp = data.iloc[:, 0]\n",
    "    \n",
    "    y = []\n",
    "    for idx, val in y_tmp.iteritems():\n",
    "        if val == '__label__2':\n",
    "            y.append(\"positive\")\n",
    "        elif val == '__label__1':\n",
    "            y.append(\"negative\")\n",
    "\n",
    "    # split train and test data\n",
    "    return train_test_split(X, y,test_size=0.15)\n",
    "\n",
    "\n",
    "def y_to_float(y):\n",
    "    y_float = []\n",
    "    #print(y)\n",
    "    for val in y:\n",
    "        if val == \"positive\":\n",
    "            y_float.append(1)\n",
    "        elif val == \"negative\":\n",
    "            y_float.append(0)\n",
    "    #print(y_float)\n",
    "    return y_float\n",
    "\n",
    "\n",
    "def run_gaussianNB(X_train, X_test, y_train, y_test):\n",
    "    y_train_f = y_to_float(y_train)\n",
    "    #print(y_train_f)\n",
    "    y_test_f = y_to_float(y_test)\n",
    "\n",
    "    # Naive Bayes\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train_f)\n",
    "\n",
    "    # predict class\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(\"GAUSSIAN NAIVE BAYES\")\n",
    "    print(confusion_matrix(y_test_f, y_pred))\n",
    "    print(classification_report(y_test_f, y_pred))\n",
    "    print(accuracy_score(y_test_f, y_pred))\n",
    "\n",
    "\n",
    "def run_multinomialNB(X_train, X_test, y_train, y_test):\n",
    "    y_train_f = y_to_float(y_train)\n",
    "    y_test_f = y_to_float(y_test)\n",
    "    tf_transformer = TfidfTransformer().fit_transform(X_train)\n",
    "\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(tf_transformer, y_train_f)\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(\"MULTINOMIAL NAIVE BAYES\")\n",
    "    print(confusion_matrix(y_test_f, y_pred))\n",
    "    print(classification_report(y_test_f, y_pred))\n",
    "    print(accuracy_score(y_test_f, y_pred))\n",
    "\n",
    "def run_bernoulliNB(X_train, X_test, y_train, y_test):\n",
    "    y_train_f = y_to_float(y_train)\n",
    "    y_test_f = y_to_float(y_test)\n",
    "\n",
    "    classifier = BernoulliNB()\n",
    "    classifier.fit(X_train, y_train_f)\n",
    "\n",
    "    #classifier.save('my_model') \n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(\"BERNOULLI NAIVE BAYES\")\n",
    "    print(confusion_matrix(y_test_f, y_pred))\n",
    "    print(classification_report(y_test_f, y_pred))\n",
    "    print(accuracy_score(y_test_f, y_pred))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = get_data_frame()\n",
    "    X_train, X_test, y_train, y_test = split_train_test(data)\n",
    "\n",
    "    #run_gaussianNB(X_train, X_test, y_train, y_test)\n",
    "    run_multinomialNB(X_train, X_test, y_train, y_test)\n",
    "    #run_bernoulliNB(X_train, X_test, y_train, y_test)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('vect',\n",
      "                 TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.float64'>,\n",
      "                                 encoding='utf-8', input='content',\n",
      "                                 lowercase=True, max_df=1.0, max_features=None,\n",
      "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
      "                                 preprocessor=None, smooth_idf=True,\n",
      "                                 stop_words=None, strip_accents=None,\n",
      "                                 sublinear_tf=False,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, use_idf=True,\n",
      "                                 vocabulary=None)),\n",
      "                ('clf',\n",
      "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
      "         verbose=False)\n",
      "0.8263473053892215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  __label__1       0.77      0.91      0.83        80\n",
      " __label__1        0.00      0.00      0.00         1\n",
      "  __label__2       0.90      0.76      0.82        86\n",
      "\n",
      "    accuracy                           0.83       167\n",
      "   macro avg       0.56      0.56      0.55       167\n",
      "weighted avg       0.83      0.83      0.82       167\n",
      "\n",
      "[[73  0  7]\n",
      " [ 1  0  0]\n",
      " [21  0 65]]\n",
      "['__label__2' '__label__1' '__label__1' '__label__2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajind\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "model = Pipeline([('vect', TfidfVectorizer()), \n",
    "                      ('clf', MultinomialNB()) ])\n",
    "#model = Pipeline([ ('vect', CountVectorizer(stop_words='english')),\n",
    "#                  ('tfidf', TfidfTransformer()),\n",
    "#                  ('clf', MultinomialNB()) ])\n",
    "#print(model)\n",
    "\n",
    "df = pd.read_csv('Sentiment_Analysis_Dataset/labelled.csv')\n",
    "df.head()\n",
    "\n",
    "X=df.drop(['Label'],axis=1)\n",
    "y=df['Label']\n",
    "#print(X.head())\n",
    "#print(y.head())\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.15)\n",
    "\n",
    "vt = Pipeline([('vect', TfidfVectorizer()), \n",
    "                      ('clf', MultinomialNB()) ])\n",
    "print(vt)\n",
    "vt.fit(X_train.transpose().apply(lambda x: ' '.join(x)),y_train)\n",
    "\n",
    "prediction = vt.predict(X_test.transpose().apply(lambda x: ' '.join(x)))\n",
    "\n",
    "print(accuracy_score(y_test, prediction))\n",
    "print(classification_report(y_test, prediction))\n",
    "print(confusion_matrix(y_test, prediction))\n",
    "\n",
    "predict=vt.predict(['The Phone was of good quality but its has a large amount of issues within it.','not so good and nor bad','Very poor phone','Lithium batteries are something new introduced in the market there average developing cost is relatively high but Stallion doesn\\'t compromise on quality and provides us with the best at a low cost.<br />There are so many in built technical assistants that act like a sensor in their particular fortÃ©. The battery keeps my phone charged up and it works at every voltage and a high voltage is never risked'])\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
